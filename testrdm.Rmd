---
title: "Group Project Telemarketing"
author: "Juliet Niebylski, Ziying Peng, Leah Sun, Ally Weingarden, Marisa Wong"
output:
  html_document:
    toc: true
    theme: readable
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Downloading and Prepping the Data

```{r}
#Downloading and Prepping the Data
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)
summary(tele)

#We are deleting the "duration" variable because it is an after the fact measurement. We only should be using variables that we know before the call
tele$duration <- NULL

# Deleting the column X
tele$X <- NULL

# Changing pdays to a dummy and deleting pdays
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1)
tele$pdays <- NULL

str(tele)
```

## Getting Data Ready for Analysis

```{r}
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric

telemm <- as.data.frame(model.matrix(~.-1,tele))
str(telemm)

# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
tele_random <- telemm[sample(nrow(telemm)),]

#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# we are going to normalize everything 
tele_norm <- as.data.frame(lapply(tele_random, normalize))
```

## K-Means Clustering

```{r}
tele_norm_k_means <- tele_norm
tele_norm_k_means$yyes <- NULL
k_means_clusters <- kmeans(tele_norm_k_means, 5)
k_means_clusters$size
k_means_clusters$centers
tele_norm_k_means$yyes <- tele_norm$yyes
tele_norm_k_means$cluster <- k_means_clusters$cluster
summary(tele_norm_k_means)

# Calculate number of 1s for yyes for each cluster
num_yyes_1 <- sum(tele_norm_k_means[tele_norm_k_means$cluster == 1,]$yyes)
num_yyes_2 <- sum(tele_norm_k_means[tele_norm_k_means$cluster == 2,]$yyes)
num_yyes_3 <- sum(tele_norm_k_means[tele_norm_k_means$cluster == 3,]$yyes)
num_yyes_4 <- sum(tele_norm_k_means[tele_norm_k_means$cluster == 4,]$yyes)
num_yyes_5 <- sum(tele_norm_k_means[tele_norm_k_means$cluster == 5,]$yyes)

# Calculate the success rate for each cluster
(success_rate_1 <- num_yyes_1 / nrow(tele_norm_k_means[tele_norm_k_means$cluster == 1,]))
(success_rate_2 <- num_yyes_2 / nrow(tele_norm_k_means[tele_norm_k_means$cluster == 2,]))
(success_rate_3 <- num_yyes_3 / nrow(tele_norm_k_means[tele_norm_k_means$cluster == 3,]))
(success_rate_4 <- num_yyes_4 / nrow(tele_norm_k_means[tele_norm_k_means$cluster == 4,]))
(success_rate_5 <- num_yyes_5 / nrow(tele_norm_k_means[tele_norm_k_means$cluster == 5,]))
```













## Getting Train and Test Samples for KNN

```{r}
# Selects 10000 random rows for test data
set.seed(12345)
test_set <- sample(1:nrow(tele_norm), 10000) 
# Depending on R-version and computer, different rows may be selected. 
# If that happens, results are different. 

# Create a train set and test set
#First the predictors - all columns except the yyes column
tele_train <- tele_norm[-test_set, -match("yyes",names(tele_norm))]
tele_test <- tele_norm[test_set, -match("yyes",names(tele_norm))]

#Now the response (aka Labels) - only the yyes column
tele_train_labels <- tele_norm[-test_set, "yyes"]
tele_test_labels <- tele_norm[test_set, "yyes"]

```

## Do KNN

```{r}
library(class)
library(caret)
# k_val <- 20 # kappa value of 0.2447
k_val <- round(sqrt(nrow(tele_train))) # kappa value of 0.1928
# k_val <- 300 # kappa value of 0.1459
tele_test_pred <- knn(train = tele_train, test = tele_test,
                      cl = tele_train_labels, k=k_val)
#Evaluate model results
library(gmodels)
CrossTable(x = tele_test_labels, y = tele_test_pred, 
           prop.chisq=FALSE)
# Evaluate confusion matrix
confusionMatrix(tele_test_pred, as.factor(tele_test_labels), positive = "1")
```


> Now you are ready to build your ANN model. Feel free to modify the data load, cleaning and preparation code above as per your preference.

## Do ANN

```{r, cache = TRUE}
# Get training and testing data
# Note: choosing 10000 values to be testing data
training_data <- tele_norm[-test_set,]
testing_data <- tele_norm[test_set,]

summary(training_data)
summary(testing_data)

# Do ANN
library(neuralnet)

model1 <- neuralnet(formula = yyes ~ ., data = training_data)
plot(model1)
prediction_values <- predict(model1, newdata = testing_data)
predictions <- ifelse(prediction_values > 0.5, 1, 0)
# Create Confusion Matrix
library(gmodels)
library(caret)
CrossTable(x = testing_data$yyes, y = predictions, propsq = FALSE)
# Evaluate confusion matrix
confusionMatrix(as.factor(predictions), as.factor(testing_data$yyes), positive = "1")

# model2 <- neuralnet(formula = yyes ~ ., data = training_data, hidden = 3)
# plot(model2)
# prediction_values2 <- predict(model2, newdata = testing_data)
# predictions2 <- ifelse(prediction_values2 > 0.5, 1, 0)
# # Create Confusion Matrix
# CrossTable(x = testing_data$yyes, y = predictions2, propsq = FALSE)
# # Evaluate confusion matrix
# confusionMatrix(as.factor(predictions2), as.factor(testing_data$yyes), positive = "1")
# 
# model3 <- neuralnet(formula = yyes ~ ., data = training_data, hidden = c(3, 2))
# plot(model3)
# prediction_values3 <- predict(model3, newdata = testing_data)
# predictions3 <- ifelse(prediction_values3 > 0.5, 1, 0)
# # Create Confusion Matrix
# CrossTable(x = testing_data$yyes, y = predictions3, propsq = FALSE)
# # Evaluate confusion matrix
# confusionMatrix(as.factor(predictions2), as.factor(testing_data$yyes), positive = "1")
```

## Do Logistic Regression

```{r}
# Create logistic regression model with all the predictor variables
glm_model <- glm(formula = yyes ~ ., data = training_data, family = "binomial")
summary(glm_model)
# Get response values for testing data
prediction_values_glm1 <- predict(glm_model, newdata = testing_data, type = "response")
# Get predictions for testing data
predictions_glm1 <- ifelse(prediction_values_glm1 > 0.5, 1, 0)
# Create Confusion Matrix
CrossTable(x = testing_data$yyes, y = predictions_glm1, propsq = FALSE)
# Evaluate confusion matrix
confusionMatrix(as.factor(predictions_glm1), as.factor(testing_data$yyes), positive = "1")
```

## Combined Model

```{r}
# Add up each row of the three predictor vectors for the three chosen models
added_predictors <- as.numeric(tele_test_pred) + predictions[,1] + predictions_glm1
predictions_combined_model <- ifelse(added_predictors >= 2, 1, 0)
# Create Confusion Matrix
CrossTable(x = testing_data$yyes, y = predictions_combined_model, propsq = FALSE)
# Evaluate confusion matrix
confusionMatrix(as.factor(predictions_combined_model), as.factor(testing_data$yyes), positive = "1")
```


## Conclusion


